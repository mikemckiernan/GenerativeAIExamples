services:

  jupyter-server:
    container_name: notebook-server
    image: notebook-server:latest
    build:
      context: ../../
      dockerfile: ./notebooks/Dockerfile.notebooks
    ports:
    - "8888:8888"
    expose:
    - "8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  evaluation:
    container_name: evaluation
    image: evalulation:latest
    build:
      context: ../../
      dockerfile: ./evaluation/Dockerfile.eval
    ports:
    - "8889:8889"
    expose:
    - "8889"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]


  query:
    container_name: chain-server
    image: chain-server:latest
    build:
      context: ../../
      dockerfile: ./RetrievalAugmentedGeneration/Dockerfile
    command: --port 8081 --host 0.0.0.0
    environment:
      RAG_EXAMPLE: ${RAG_EXAMPLE}
      NVIDIA_API_KEY: ${NVIDIA_API_KEY}
    ports:
    - "8081:8081"
    expose:
    - "8081"
    shm_size: 5gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  frontend:
    container_name: llm-playground
    image: llm-playground:latest
    build:
      context: ../.././RetrievalAugmentedGeneration/frontend/
      dockerfile: Dockerfile
    command: --port 8090
    environment:
      APP_SERVERURL: http://query
      APP_SERVERPORT: 8081
      APP_MODELNAME: ${MODEL_NAME:-${MODEL_ARCHITECTURE}}
    ports:
    - "8090:8090"
    expose:
    - "8090"
    depends_on:
      - query

networks:
  default:
    name: nvidia-llm
