# full path to the local copy of the model weights
# NOTE: This should be an absolute path and not relative path
export MODEL_DIRECTORY="/home/nvidia/llama-2-13b-chat_vLLAMA-2-13B-CHAT-4K-FP16-1-A100.24.01/model-store"

# Fill this out if you dont have a GPU. Leave this empty if you have a local GPU
export NVIDIA_API_KEY="nvapi-*"

# the name of the model being used - only for displaying on frontend
export MODEL_NAME="Llama-2-13b-chat-hf"

# [OPTIONAL] the number of GPUs to make available to the inference server
# export INFERENCE_GPU_COUNT="all"

# [OPTIONAL] the base directory inside which all persistent volumes will be created
# export DOCKER_VOLUME_DIRECTORY="."

# [OPTIONAL] the config file for chain server w.r.t. pwd
export APP_CONFIG_FILE=/dev/null

# parameters for PGVector, update this when using PGVector Vector store
# export POSTGRES_PASSWORD=password
# export POSTGRES_USER=postgres
# export POSTGRES_DB=api

# Update this line when using an external PGVector Vector store
# export POSTGRES_HOST_IP=pgvector
# export POSTGRES_PORT_NUMBER=5432

### Riva Parameters:

# Riva Speech API URI: Riva Server IP address/hostname and port
export RIVA_API_URI=""

# [OPTIONAL] Riva Speech API Key
# If necessary, enter a key to access the Riva API
export RIVA_API_KEY=""

# [OPTIONAL] Riva Function ID
# If necessary, enter a function ID to access the Riva API
export RIVA_FUNCTION_ID=""

# TTS sample rate (Hz)
export TTS_SAMPLE_RATE=48000

# [OPTIONAL] full path to the model store directory storing the nemo embedding model
export EMBEDDING_MODEL_DIRECTORY="/home/nvidia/nv-embed-qa_v003"

# [OPTIONAL] name of the nemo embedding model
export EMBEDDING_MODEL_NAME="NV-Embed-QA"
export EMBEDDING_MODEL_CKPT_NAME="NV-Embed-QA-003.nemo"

# csv prompt name to be used for csv rag example
export CSV_NAME="PdM_machines"